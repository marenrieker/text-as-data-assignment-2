---
title: "TaD Assignment 2"
author: "Maren Rieker"
date: "2022-11-11"
output: html_document
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      eval = TRUE,
                      error = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      comment = NA)
```

Setup
```{r, include = T}
library(manifestoR)
mp_setapikey("manifesto_apikey.txt")
library(tm)
library(tidyverse)
library(quanteda)
library(topicmodels)
library(tidytext)
library(LDAvis)
library(servr)
```


# (1) Data acquisition, description and preparation

## 1.1 Data acquisition and description

```{r}
#create a dataframe to access more information
dfmpds <- data.frame(mp_maindataset(version = "MPDS2022a"))

#find out the party codes of parties of interest
mpds_de <- dfmpds %>% 
  subset(countryname == "Germany") %>% 
  select(party, partyname) %>% 
  distinct()

mpds_de <- dfmpds %>% 
  filter(countryname == "Germany" 
         & date >= 201301
         & party != "41952" #taking the pirates out of the dataset
         & party != "41912" #same for the ssw
         & party != "41320" #and spd
         & party != "41521" #and cdu
         & party != "41223") #and linke 

mpds <- mp_corpus(countryname == "Germany"
                  & date >= 201301
                  & party != "41952"
                  & party != "41912"
                  & party != "41320"
                  & party != "41521"
                  & party != "41223")

#because my research question will focus on parties, the data needs to be adjusted
deta_frame <- mpds %>% 
  names() %>% 
  map_dfr(function(x) mpds[[x]]$content %>% 
            cbind(mpds[[x]]$meta$party) %>%
            cbind(mpds[[x]]$meta$manifesto_id)) %>% 
  rename("party" = "mpds[[x]]$meta$party",
         "manifesto_id" = "mpds[[x]]$meta$manifesto_id")

deta_frame <- deta_frame %>% 
  mutate(year = str_extract(manifesto_id, "\\d{6}")) %>% 
  group_by(party, year) %>% 
  summarize(text = paste(text, collapse = " "))

colnames(deta_frame)
```

## 1.2 Years, countries and parties in the data set and how many texts there are for each of these

Years
```{r}
mpds_de %>% 
  distinct(date)

mpyear <- table(mpds_de$date) %>% 
  as.data.frame() %>% 
  arrange(desc(Freq))
mpyear
```

There are three elections in three years in the data set, ranging from 2013 to 2021. In each election year, there are three manifestos.

Countries
```{r}
mpds_de %>% 
  distinct(countryname)

mpcountry <- table(mpds_de$countryname) %>% 
  as.data.frame() %>% 
  arrange(desc(Freq))
mpcountry
```
I have included one country in the dataset, Germany. Nine manifestos are included for Germany.

Parties
```{r}
mpds_de %>% 
  distinct(partyabbrev)

mpparty <- table(mpds_de$partyabbrev) %>% 
  as.data.frame() %>% 
  arrange(desc(Freq))
mpparty
```

There are three parties in the dataset. Because of the theoretical background of my research question, only these parties are included, as I assume that they represent both sides of the cleavage in Germany.

```{r}
#create the corpus, including the relevant German parties since 1990
mpc <- corpus(deta_frame$text,
              docvars = data.frame(deta_frame$party, deta_frame$year))

head(docvars(mpc)) #the last run gives only two parties - but I unfortunately do not have time to fix this and this error renders the whole analysis even more useless than it was before.
```

The dataset I compiled contains the three relevant parties to the new cleavage between authoritarian-populism and liberal-pluralism on a national level in Germany since 2013 The year 2013 was chosen as the right-wing populist AfD was established then and took part in elections for the first time. I excluded the manifesto of the Pirates because only one manifesto was included and they have only been politically relevant for a short point in time - and the SSW (Südschleswigscher Wählerverband) was excluded because they only hold one mandate in national parliament and are only present in one state, resulting in very little influence to national debates.

## 1.3 Preparing the data for topic modelling with a document feature matrix

```{r}
#tokenisation
tokens_de <- mpc %>%
  tokens() %>% 
  tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
  tokens_tolower() %>%
  tokens_remove(stopwords("de")) %>% 
  tokens_wordstem(language = "de") %>% 
  tokens_remove(c("muss", "dass", "deshalb", "sich", "dafur", "setz", "soll", "mehr", "stark", "programm", "deutschland"))

tokens_de <- tokens_select(tokens_de, min_nchar = 4L) #excluding party names

#document-feature-matrix
token_dfm <- tokens_de %>% 
  dfm()

manifesto_dfm <- dfm_group(token_dfm, 
                          groups = interaction(deta_frame.party,
                                               deta_frame.year))
manifesto_dfm
```


# (2) Research question: 
*Which topics dominate the modern cleavage between populist-authorianism and liberal pluralism in party manifestos in Germany?*

The question I'm going to explore using topic modelling concerns cleavages in the modern party system of Germany. Generally, the cleavage theory was first formulated by Lipset and Rokkan in the 1960s, where they identified four dimensions of cleavages where parties have historically emerged. Keeping dealignment processes in Western societies after World War 2 in mind, scholars now are speaking about a new cleavage emerging.
This new cleavage runs between liberal pluralists that have a positive attitude towards issues such as gender equality, migration, diversity and parliamentary democracy. Authoritarian populists, on the other hand, are fundamentally hostile to these issues, wish to uphold traditional values, keep the nation pure and often call for more direct democracy due to attitudes critical of the elite.

The Manifesto Project Database serves as a solid data foundation for my research question (and most questions concerned with party positions in general, I would say). They serve as a relatively neutral formulation of parties' plans and positions for a wide range of topics, while not being as polemised as for example Social Media updates or Talkshow appearances of single personalities within a party.
Moving on from the data source and having a closer look at the data I will actually feed my model, time will have to show whether I can make meaningful assumptions from the data to answer my research question. Constructing the document-feature-matrix was very painful and I am not sure if I got lost or actually managed to include all the information that I need to answer this question. The biggest challenge was whether the necessary information is in the end accessible to model party manifesto content by party.
Sentiment analysis would probably come in very handy here to see differences in parties' view points, but if they are writing on these topics generally though and in which frequency shows that they have them on the agenda nonetheless - following the theory, parties from both sides of the cleavage have to be concerned with the same topics and just have different opinions on them.


# (3) Topic model development

## 3.1 Setting the model up
I choose Latent Dirichlet Allocation (LDA) with three topics at first
```{r}
lda1 <- LDA(manifesto_dfm, k = 2, control = list(seed = 1234))
lda1

thtopics <- tidy(lda1, matrix = "beta")
thtopics

thtopics_top_terms <- thtopics %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>% 
  ungroup() %>%
  arrange(topic, -beta)

thtopics_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered()
```

Then see if and how the results change with ten topics:
```{r}
lda2 <- LDA(manifesto_dfm, k = 10, control = list(seed = 1234))
lda2

tentopics <- tidy(lda2, matrix = "beta")
tentopics

tentopics_top_terms <- tentopics %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>% 
  ungroup() %>%
  arrange(topic, -beta)

tentopics_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered()
```

Now once more with 5:
```{r}
lda3 <- LDA(manifesto_dfm, k = 5, control = list(seed = 1234))
lda3

twtopics <- tidy(lda3, matrix = "beta")

twtopics_top_terms <- twtopics %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>% 
  ungroup() %>%
  arrange(topic, -beta)

twtopics_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered()
```

## 3.2 What did the model do?

Explanation of what the model does:
In LDA, the examined corpus is considered in two levels: First, every document is seen as a mixture of topics, while second, every topic consists of a mixture of words. The algorithm in LDA basically examines both levels at the same time and can therefore give insights into the proportion different topics have in the examined documents and of which words they consist.
It is important to note that one word can belong to several topics - coming in handy for the examination of party manifestos, where one can expect for some words to be used by every party and across different topics.

## 3.3 Hyperparameter selection
The only Hyperparameter tuning done was the optimisation of k, the number of topics until they seemed coherent. While there is not so much tuning to be done to the LDA model itself, the results also show that lemmatization might have been a better choice in preprocessing than simply stemming the words.

# (4) Topic model description

```{r}
doc_topics <- tidy(lda3, matrix = "gamma") %>% 
  left_join(deta_frame %>% 
              mutate(document = paste0(party, ".", year))) %>% 
  separate(document, into = c('party_id', 'yearmonth')) %>% 
  mutate(year = str_extract(yearmonth, '\\d{4}'))

as.numeric(doc_topics$year)


yearly_topics <- doc_topics %>%
  group_by(year, topic, party) %>%
  summarise(gamma = sum(gamma)) %>%
  group_by(year) %>%
  mutate(year_share = gamma/sum(gamma)) %>%
  ungroup() %>%
  mutate(topic = factor(topic))
yearly_topics

colnames(yearly_topics)

ggplot(filter(yearly_topics,
              topic %in% c(1, 5)), 
       aes(x = year, 
           y = year_share, 
           group = topic, 
           colour = topic, 
           fill = topic)) + geom_line()
```
At the last code run, this plot does not make much sense, honestly it also did not bring too much enlightenment in the second to last run.
My intention here was to choose two topics from the lda3-model that seem distinct and plot how big their share was in the last three elections of all topics.


# (5) Answering my research question

With the approach I took, I could not answer my research question. As can be seen in the results, the LDA-model (or my interpretation of it) did not bring any significant findings.
There were for sure mistakes in the way I preprocessed the data, with collapsing all manifestos of a party in one row - this step certainly made the topic division less meaningful and the topics themselves less distinct. But keeping the data in a format closer to the one in the downloaded corpus, made a party-based analysis quite fiddly and difficult. Maybe this could have been prevented by me not choosing to do LDA, but a stm-model and keep the party information as metadata.



