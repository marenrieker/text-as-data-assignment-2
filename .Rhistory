dfm_group(cmp_code) %>%
dfm_weight(scheme = "prop") %>%
dfm_subset(cmp_code %in% c("301", "110", "108"))
View(mpds_de)
"per605_2" %in% names(mpc)
"per605_2" %in% names(mpds_de)
#document-feature-matrix
manifesto_dfm <- tokens_de %>%
dfm() %>%
dfm_subset(!(cmp_code %in% c("H", "", "0", "000", NA))) %>% #exclude na, headlines or uncoded quasi-sentences
dfm_group(cmp_code) %>%
dfm_weight(scheme = "prop") %>% #count the proportion of word per document
dfm_subset(cmp_code %in% c("per103", "per104", "per105", "per107", "per108", "per109", "per110", "per201", "per202", "per304", "per305", "per406", "per407", "per411", "per413", "per501", "per502", "per503", "per506", "per507", "per601", "per602", "per603", "per604", "per605", "per606", "per607", "per608", "per705", "per706", "per1011", "per1012", "per1021", "per1022", "per2022", "per2023", "per6013", "per6061", "per6071", "per7062", "per201_1", "per201_2", "per202_3", "per202_4", "per416_2", "per601_1", "per601_2", "per602_1", "per602_2", "per605_1", "per605_2", "per606_1", "per606_2", "per607_1", "per607_2", "per608_1", "per608_2"))
manifesto_dfm
manifesto_dfm
dfmat <- tokens_de %>%
dfm()
dfmat
dfmat <- tokens_de %>%
dfm() %>%
dfm_subset(!(cmp_code %in% c("H", "", "0", "000", NA))) %>% #exclude na, headlines or uncoded quasi-sentences
dfm_group(cmp_code) %>%
dfm_weight(scheme = "prop")
dfmat
dfmat <- tokens_de %>%
dfm() %>%
dfm_subset(!(cmp_code %in% c("H", "", "0", "000", NA))) %>% #exclude na, headlines or uncoded quasi-sentences
dfm_group(cmp_code) %>%
dfm_weight(scheme = "prop")%>% #count the proportion of word per document
dfm_subset(cmp_code %in% c("per103", "per104", "per105", "per107", "per108", "per109", "per110", "per201", "per202", "per304", "per305", "per406", "per407", "per411", "per413", "per501", "per502", "per503", "per506", "per507", "per601", "per602", "per603", "per604", "per605", "per606", "per607", "per608", "per705", "per706", "per1011", "per1012", "per1021", "per1022", "per2022", "per2023", "per6013", "per6061", "per6071", "per7062", "per201_1", "per201_2", "per202_3", "per202_4", "per416_2", "per601_1", "per601_2", "per602_1", "per602_2", "per605_1", "per605_2", "per606_1", "per606_2", "per607_1", "per607_2", "per608_1", "per608_2"))
dfmat
#document-feature-matrix
manifesto_dfm <- tokens_de %>%
dfm() %>%
dfm_subset(!(cmp_code %in% c("H", "", "0", "000", NA))) %>% #exclude na, headlines or uncoded quasi-sentences
dfm_group(cmp_code) %>%
dfm_weight(scheme = "prop") %>% #count the proportion of word per document
#  dfm_subset(cmp_code %in% c("per103", "per104", "per105", "per107", "per108", "per109", "per110", "per201", "per202", "per304", "per305", #"per406", "per407", "per411", "per413", "per501", "per502", "per503", "per506", "per507", "per601", "per602", "per603", "per604", "per605", #"per606", "per607", "per608", "per705", "per706", "per1011", "per1012", "per1021", "per1022", "per2022", "per2023", "per6013", "per6061", #"per6071", "per7062", "per201_1", "per201_2", "per202_3", "per202_4", "per416_2", "per601_1", "per601_2", "per602_1", "per602_2", "per605_1", #"per605_2", "per606_1", "per606_2", "per607_1", "per607_2", "per608_1", "per608_2"))
manifesto_dfm
#document-feature-matrix
manifesto_dfm <- tokens_de %>%
dfm() %>%
dfm_subset(!(cmp_code %in% c("H", "", "0", "000", NA))) %>% #exclude na, headlines or uncoded quasi-sentences
dfm_group(cmp_code) %>%
dfm_weight(scheme = "prop") #%>% #count the proportion of word per document
#  dfm_subset(cmp_code %in% c("per103", "per104", "per105", "per107", "per108", "per109", "per110", "per201", "per202", "per304", "per305", #"per406", "per407", "per411", "per413", "per501", "per502", "per503", "per506", "per507", "per601", "per602", "per603", "per604", "per605", #"per606", "per607", "per608", "per705", "per706", "per1011", "per1012", "per1021", "per1022", "per2022", "per2023", "per6013", "per6061", #"per6071", "per7062", "per201_1", "per201_2", "per202_3", "per202_4", "per416_2", "per601_1", "per601_2", "per602_1", "per602_2", "per605_1", #"per605_2", "per606_1", "per606_2", "per607_1", "per607_2", "per608_1", "per608_2"))
manifesto_dfm
#document-feature-matrix
manifesto_dfm <- tokens_de %>%
dfm() %>%
dfm_subset(!(cmp_code %in% c("H", "", "0", "000", NA))) %>% #exclude na, headlines or uncoded quasi-sentences
dfm_group(cmp_code) #%>%
#  dfm_weight(scheme = "prop") #%>% #count the proportion of word per document
#  dfm_subset(cmp_code %in% c("per103", "per104", "per105", "per107", "per108", "per109", "per110", "per201", "per202", "per304", "per305", #"per406", "per407", "per411", "per413", "per501", "per502", "per503", "per506", "per507", "per601", "per602", "per603", "per604", "per605", #"per606", "per607", "per608", "per705", "per706", "per1011", "per1012", "per1021", "per1022", "per2022", "per2023", "per6013", "per6061", #"per6071", "per7062", "per201_1", "per201_2", "per202_3", "per202_4", "per416_2", "per601_1", "per601_2", "per602_1", "per602_2", "per605_1", #"per605_2", "per606_1", "per606_2", "per607_1", "per607_2", "per608_1", "per608_2"))
manifesto_dfm
#document-feature-matrix
manifesto_dfm <- tokens_de %>%
dfm() %>%
dfm_subset(!(cmp_code %in% c("H", "", "0", "000", NA))) %>% #exclude na, headlines or uncoded quasi-sentences
dfm_group(cmp_code) %>%
dfm_weight(scheme = "prop") #%>% #count the proportion of word per document
#  dfm_subset(cmp_code %in% c("per103", "per104", "per105", "per107", "per108", "per109", "per110", "per201", "per202", "per304", "per305", #"per406", "per407", "per411", "per413", "per501", "per502", "per503", "per506", "per507", "per601", "per602", "per603", "per604", "per605", #"per606", "per607", "per608", "per705", "per706", "per1011", "per1012", "per1021", "per1022", "per2022", "per2023", "per6013", "per6061", #"per6071", "per7062", "per201_1", "per201_2", "per202_3", "per202_4", "per416_2", "per601_1", "per601_2", "per602_1", "per602_2", "per605_1", #"per605_2", "per606_1", "per606_2", "per607_1", "per607_2", "per608_1", "per608_2"))
manifesto_dfm
install.packages("stm"")
library(stm)
knitr::opts_chunk$set(echo = T)
library(manifestoR)
mp_setapikey("manifesto_apikey.txt")
knitr::opts_chunk$set(echo = F)
library(manifestoR)
mp_setapikey("manifesto_apikey.txt")
library(tm)
library(tidyverse)
library(quanteda)
library(topicmodels)
library(tidytext)
library(stm)
?stm_tidiers
library(tidytext)
?stim()
?stm
try_stm <- stm(manifesto_dfm, 10, prevalence = s(party, date))
try_stm <- stm(manifesto_dfm, K = 10, prevalence = s(party, date))
#document-feature-matrix
manifesto_dfm <- tokens_de %>%
dfm() %>%
dfm_subset(!(cmp_code %in% c("H", "", "0", "000", NA))) %>% #exclude na, headlines or uncoded quasi-sentences
dfm_group(cmp_code)# %>%
#  dfm_weight(scheme = "prop") #%>% #count the proportion of word per document - kann stm glaube ich auch!
#  dfm_subset(cmp_code %in% c("per103", "per104", "per105", "per107", "per108", "per109", "per110", "per201", "per202", "per304", "per305", #"per406", "per407", "per411", "per413", "per501", "per502", "per503", "per506", "per507", "per601", "per602", "per603", "per604", "per605", #"per606", "per607", "per608", "per705", "per706", "per1011", "per1012", "per1021", "per1022", "per2022", "per2023", "per6013", "per6061", #"per6071", "per7062", "per201_1", "per201_2", "per202_3", "per202_4", "per416_2", "per601_1", "per601_2", "per602_1", "per602_2", "per605_1", #"per605_2", "per606_1", "per606_2", "per607_1", "per607_2", "per608_1", "per608_2"))
manifesto_dfm
try_stm <- stm(manifesto_dfm, K = 10, prevalence = s(party, date))
try_stm <- stm(manifesto_dfm, K = 10, prevalence = s(date))
try_stm <- stm(manifesto_dfm, K = 10)
try_stm <- stm(manifesto_dfm, K = 10, max.em.its = 50)
library(manifestoR)
knitr::opts_chunk$set(echo = F)
library(manifestoR)
mp_setapikey("manifesto_apikey.txt")
library(tm)
library(tidyverse)
library(quanteda)
library(readtext)
library(topicmodels)
library(tidytext)
library(stm)
```{r, include = TRUE}
#create a dataframe to access more information
dfmpds <- data.frame(mp_maindataset(version = "MPDS2022a"))
#find out the party codes of parties of interest
mpds_de <- dfmpds %>%
subset(countryname == "Germany") %>%
select(party, partyname) %>%
distinct()
mpds_de <- dfmpds %>%
filter(countryname == "Germany"
& date >= 199001
& party != "41952" #taking the pirates out of the dataset
& party != "41912") #same for the ssw
#create the corpus, including the relevant German parties since 1990
mpds <- mp_corpus(countryname == "Germany"
& date >= 199001
& party != "41952"
& party != "41912")
mpc <- mpds %>%
as.data.frame(with.meta = TRUE) %>%
corpus(docid_field = "manifesto_id", unique_docnames = FALSE) %>%
corpus()
#tokenisation
tokens_de <- mpc %>%
tokens() %>%
tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(stopwords("de")) %>%
tokens_wordstem()
tokens_de <- tokens_select(tokens_de, min_nchar=4L) #excluding party names
#document-feature-matrix
manifesto_dfm <- tokens_de %>%
dfm() %>%
dfm_subset(!(cmp_code %in% c("H", "", "0", "000", NA))) %>% #exclude na, headlines or uncoded quasi-sentences
#  dfm_subset(cmp_code %in% c("per103", "per104", "per105", "per107", "per108", #"per109", "per110", "per201", "per202", "per304", "per305", "per406", #"per407", "per411", "per413", "per501", "per502", "per503", "per506", #"per507", "per601", "per602", "per603", "per604", "per605", "per606", #"per607", "per608", "per705", "per706", "per1011", "per1012", "per1021", #"per1022", "per2022", "per2023", "per6013", "per6061", "per6071", "per7062", #"per201_1", "per201_2", "per202_3", "per202_4", "per416_2", "per601_1", #"per601_2", "per602_1", "per602_2", "per605_1", "per605_2", "per606_1", #"per606_2", "per607_1", "per607_2", "per608_1", "per608_2")) %>%
dfm_group(cmp_code)
manifesto_dfm
View(mpds_de)
View(mpds)
View(mpds_de)
mpds_cmp <- mpds_de %>%
subset(per103, per104, per105, per107, per108, per109, per110, per201, per202, per304, per305, per406, per407, per411, per413, per501, per502, per503, per506, per507, per601, per602, per603, per604, per605, per606, per607, per608, per705, per706, per1011, per1012, per1021, per1022, per2022, per2023, per6013, per6061, per6071, per7062, per201_1, per201_2, per202_3, per202_4, per416_2, per601_1, per601_2, per602_1, per602_2, per605_1, per605_2, per606_1, per606_2, per607_1, per607_2, per608_1, per608_2)
mpds_cmp <- mpds_de %>%
subset(select = c(per103, per104, per105, per107, per108, per109, per110, per201, per202, per304, per305, per406, per407, per411, per413, per501, per502, per503, per506, per507, per601, per602, per603, per604, per605, per606, per607, per608, per705, per706, per1011, per1012, per1021, per1022, per2022, per2023, per6013, per6061, per6071, per7062, per201_1, per201_2, per202_3, per202_4, per416_2, per601_1, per601_2, per602_1, per602_2, per605_1, per605_2, per606_1, per606_2, per607_1, per607_2, per608_1, per608_2))
View(mpds_cmp)
mpds_cmp <- mpds_de %>%
subset(select = c(date, party, partyabbrev, per103, per104, per105, per107, per108, per109, per110, per201, per202, per304, per305, per406, per407, per411, per413, per501, per502, per503, per506, per507, per601, per602, per603, per604, per605, per606, per607, per608, per705, per706, per1011, per1012, per1021, per1022, per2022, per2023, per6013, per6061, per6071, per7062, per201_1, per201_2, per202_3, per202_4, per416_2, per601_1, per601_2, per602_1, per602_2, per605_1, per605_2, per606_1, per606_2, per607_1, per607_2, per608_1, per608_2))
mpc <- mpds_cmp %>%
as.data.frame(with.meta = TRUE) %>%
corpus(docid_field = "manifesto_id", unique_docnames = FALSE) %>%
corpus()
#tokenisation
tokens_de <- mpds_cmp %>%
tokens() %>%
tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(stopwords("de")) %>%
tokens_wordstem()
#tokenisation
tokens_de <- mpc %>%
tokens() %>%
tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(stopwords("deutsch")) %>%
tokens_wordstem()
#create the corpus, including the relevant German parties since 1990
mpds <- mp_corpus(countryname == "Germany"
& date >= 199001
& party != "41952"
& party != "41912")
mpc <- mpds %>%
as.data.frame(with.meta = TRUE) %>%
corpus(docid_field = "manifesto_id", unique_docnames = FALSE) %>%
corpus()
#tokenisation
tokens_de <- mpc %>%
tokens() %>%
tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(stopwords("deutsch")) %>%
tokens_wordstem()
?stopwords_getlanguages
#tokenisation
tokens_de <- mpc %>%
tokens() %>%
tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(stopwords("de")) %>%
tokens_wordstem()
#document-feature-matrix
manifesto_dfm <- tokens_de %>%
dfm() %>%
dfm_subset(!(cmp_code %in% c("H", "", "0", "000", NA))) %>% #exclude na, headlines or uncoded quasi-sentences
#  dfm_subset(cmp_code %in% c("per103", "per104", "per105", "per107", "per108", #"per109", "per110", "per201", "per202", "per304", "per305", "per406", #"per407", "per411", "per413", "per501", "per502", "per503", "per506", #"per507", "per601", "per602", "per603", "per604", "per605", "per606", #"per607", "per608", "per705", "per706", "per1011", "per1012", "per1021", #"per1022", "per2022", "per2023", "per6013", "per6061", "per6071", "per7062", #"per201_1", "per201_2", "per202_3", "per202_4", "per416_2", "per601_1", #"per601_2", "per602_1", "per602_2", "per605_1", "per605_2", "per606_1", #"per606_2", "per607_1", "per607_2", "per608_1", "per608_2")) %>%
dfm_group(cmp_code)
manifesto_dfm
head(docvars(mpc))
#tokenisation
tokens_de <- mpc %>%
tokens() %>%
tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(stopwords("de")) %>%
tokens_wordstem()
#tokenisation
tokens_de <- mpc %>%
tokens() %>%
tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(stopwords("de")) %>%
tokens_wordstem()
tokens_de <- tokens_select(tokens_de, min_nchar=4L) #excluding party names
knitr::opts_chunk$set(echo = F)
library(manifestoR)
mp_setapikey("manifesto_apikey.txt")
library(tm)
library(tidyverse)
library(quanteda)
library(topicmodels)
library(tidytext)
library(stm)
mpc_rel <- mpc %>%
corpus_subset(cmp_code %in% c("per103", "per104", "per105", "per107", "per108", "per109", "per110", "per201", "per202", "per304", "per305", "per406", "per407", "per411", "per413", "per501", "per502", "per503", "per506", "per507", "per601", "per602", "per603", "per604", "per605", "per606", "per607", "per608", "per705", "per706", "per1011", "per1012", "per1021", "per1022", "per2022","per2023", "per6013", "per6061", "per6071", "per7062", "per201_1", "per201_2", "per202_3", "per202_4", "per416_2", "per601_1", "per601_2", "per602_1", "per602_2", "per605_1", "per605_2", "per606_1", "per606_2", "per607_1", "per607_2", "per608_1", "per608_2"))
head(docvars(mpc_rel))
head(docvars(mpc))
head(docvars(mpc))
?unique_docnames
?corpus
mpc <- mpds %>%
as.data.frame(with.meta = TRUE) %>%
corpus(docid_field = "manifesto_id", unique_docnames = FALSE, meta = party) %>%
corpus()
mpc <- mpds %>%
as.data.frame(with.meta = TRUE) %>%
corpus(docid_field = "manifesto_id", unique_docnames = FALSE, meta = "partyabbrev") %>%
corpus()
head(docvars(mpc))
is.na(cmp_code)
is.na(mpc$cmp_code)
head(mpc)
head(mpc_rel)
#document-feature-matrix
manifesto_dfm <- tokens_de %>%
dfm() %>%
dfm_subset(!(cmp_code %in% c("H", "", "0", "000", NA))) %>%
dfm_group(cmp_code)
manifesto_dfm <- tokens_de %>%
dfm() %>%
dfm_subset(!(cmp_code %in% c("H", "", "0", "000", NA))) %>%
dfm_group()
#document-feature-matrix
manifesto_dfm <- tokens_de %>%
dfm() %>%
dfm_subset(!(cmp_code %in% c("H", "", "0", "000", NA))) %>%
dfm_group(cmp_code)
manifesto_dfm
manifesto_dfm <- tokens_de %>%
dfm() %>%
dfm_subset(!(cmp_code %in% c("H", "", "0", "000", NA))) %>%
dfm_group()
manifesto_dfm <- tokens_de %>%
dfm() %>%
dfm_subset(!(cmp_code %in% c("H", "", "0", "000", NA))) %>%
dfm_group()
manifesto_dfm
#document-feature-matrix
manifesto_dfm <- tokens_de %>%
dfm() %>%
dfm_subset(!(cmp_code %in% c("H", "", "0", "000", NA))) %>%
dfm_group(cmp_code)
manifesto_dfm
mpds_de %>%
distinct(date)
mpds_de %>%
distinct(date, title)
mpds_de %>%
distinct(date, text)
mpds_de %>%
distict(country)
mpds_de %>%
distinct(country)
mpds_de %>%
distinct(countryname)
mpds_de %>%
distinct(partyabbrev)
partyabbrev[f] <- "90/Greens"
mpds_de <- within(df, {
f <- party == "41112"
party[f] <- "41113"
partyabbrev[f] <- "90/Greens"
})
mpds_de <- within(mpds_de, {
f <- party == "41112"
party[f] <- "41113"
partyabbrev[f] <- "90/Greens"
})
mpds_de <- within(mpds_de, {
f <- party == "41221"  | party == "41222"
party[f] <- "41223"
partyabbrev[f] <- "LINKE"
})
mpds_de %>%
distinct(partyabbrev)
knitr::opts_chunk$set(echo = F)
library(manifestoR)
mp_setapikey("manifesto_apikey.txt")
library(tm)
library(tidyverse)
library(quanteda)
library(topicmodels)
library(tidytext)
mpds_de %>%
distinct(date)
knitr::opts_chunk$set(echo = TRUE,
eval = TRUE,
error = FALSE,
message = FALSE,
warning = FALSE,
comment = NA)
library(manifestoR)
mp_setapikey("manifesto_apikey.txt")
library(tm)
library(tidyverse)
library(quanteda)
library(topicmodels)
library(tidytext)
library(LDAvis)
library(servr)
#create a dataframe to access more information
dfmpds <- data.frame(mp_maindataset(version = "MPDS2022a"))
#find out the party codes of parties of interest
mpds_de <- dfmpds %>%
subset(countryname == "Germany") %>%
select(party, partyname) %>%
distinct()
mpds_de <- dfmpds %>%
filter(countryname == "Germany"
& date >= 201301
& party != "41952" #taking the pirates out of the dataset
& party != "41912" #same for the ssw
& party != "41320" #and spd
& party != "41521" #and cdu
& party != "41223") #and linke
mpds <- mp_corpus(countryname == "Germany"
& date >= 201301
& party != "41952"
& party != "41912"
& party != "41320"
& party != "41521"
& party != "41223")
#because my research question will focus on parties, the data needs to be adjusted
deta_frame <- mpds %>%
names() %>%
map_dfr(function(x) mpds[[x]]$content %>%
cbind(mpds[[x]]$meta$party) %>%
cbind(mpds[[x]]$meta$manifesto_id)) %>%
rename("party" = "mpds[[x]]$meta$party",
"manifesto_id" = "mpds[[x]]$meta$manifesto_id")
deta_frame <- deta_frame %>%
mutate(year = str_extract(manifesto_id, "\\d{6}")) %>%
group_by(party, year) %>%
summarize(text = paste(text, collapse = " "))
colnames(deta_frame)
mpds_de %>%
distinct(date)
mpyear <- table(mpds_de$date) %>%
as.data.frame() %>%
arrange(desc(Freq))
mpyear
mpds_de %>%
distinct(countryname)
mpcountry <- table(mpds_de$countryname) %>%
as.data.frame() %>%
arrange(desc(Freq))
mpcountry
mpds_de %>%
distinct(partyabbrev)
mpparty <- table(mpds_de$partyabbrev) %>%
as.data.frame() %>%
arrange(desc(Freq))
mpparty
#tokenisation
tokens_de <- mpc %>%
tokens() %>%
tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(stopwords("de")) %>%
tokens_wordstem(language = "de") %>%
tokens_remove(c("muss", "dass", "deshalb", "sich", "dafur", "setz", "soll", "mehr", "stark", "programm", "deutschland"))
#create the corpus, including the relevant German parties since 1990
mpc <- corpus(deta_frame$text,
docvars = data.frame(deta_frame$party, deta_frame$year))
head(mpc)
head(docvars(mpc))
#create the corpus, including the relevant German parties since 1990
mpc <- corpus(deta_frame$text,
docvars = data.frame(deta_frame$party, deta_frame$year))
head(mpc)
head(docvars(mpc))
#tokenisation
tokens_de <- mpc %>%
tokens() %>%
tokens(remove_punct = TRUE, remove_numbers = TRUE) %>%
tokens_tolower() %>%
tokens_remove(stopwords("de")) %>%
tokens_wordstem(language = "de") %>%
tokens_remove(c("muss", "dass", "deshalb", "sich", "dafur", "setz", "soll", "mehr", "stark", "programm", "deutschland"))
tokens_de <- tokens_select(tokens_de, min_nchar = 4L) #excluding party names
#document-feature-matrix
token_dfm <- tokens_de %>%
dfm()
manifesto_dfm <- dfm_group(token_dfm,
groups = interaction(deta_frame.party,
deta_frame.year))
manifesto_dfm
lda1 <- LDA(manifesto_dfm, k = 2, control = list(seed = 1234))
lda1
thtopics <- tidy(lda1, matrix = "beta")
thtopics
thtopics_top_terms <- thtopics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
thtopics_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
lda2 <- LDA(manifesto_dfm, k = 10, control = list(seed = 1234))
lda2
tentopics <- tidy(lda2, matrix = "beta")
tentopics
tentopics_top_terms <- tentopics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
tentopics_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
lda3 <- LDA(manifesto_dfm, k = 5, control = list(seed = 1234))
lda3
twtopics <- tidy(lda3, matrix = "beta")
twtopics_top_terms <- twtopics %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
twtopics_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
doc_topics <- tidy(lda3, matrix = "gamma") %>%
left_join(deta_frame %>%
mutate(document = paste0(party, ".", year))) %>%
separate(document, into = c('party_id', 'yearmonth')) %>%
mutate(year = str_extract(yearmonth, '\\d{4}'))
as.numeric(doc_topics$year)
yearly_topics <- doc_topics %>%
group_by(year, topic, party) %>%
summarise(gamma = sum(gamma)) %>%
group_by(year) %>%
mutate(year_share = gamma/sum(gamma)) %>%
ungroup() %>%
mutate(topic = factor(topic))
yearly_topics
colnames(yearly_topics)
ggplot(filter(yearly_topics,
topic %in% c(3, 5)),
aes(x = year,
y = year_share,
group = topic,
colour = topic,
fill = topic)) + geom_line()
ggplot(filter(yearly_topics,
topic %in% c(1, 5)),
aes(x = year,
y = year_share,
group = topic,
colour = topic,
fill = topic)) + geom_line()
topicmodels2LDAvis <- function(x, ...){
post <- topicmodels::posterior(x)
if (ncol(post[["topics"]]) < 3) stop("The model must contain > 2 topics")
mat <- x@wordassignments
json <- LDAvis::createJSON(
phi = post[["terms"]],
theta = post[["topics"]],
vocab = colnames(post[["terms"]]),
doc.length = slam::row_sums(mat, na.rm = TRUE),
term.frequency = slam::col_sums(mat, na.rm = TRUE)
)
return(json)
}
json <- topicmodels2LDAvis(lda3)
serVis(json)
prob_topic <- as.data.frame(topicmodels::posterior(tidy_lda)$topics)
tidy_lda <- tidy(lda3)
prob_topic <- as.data.frame(topicmodels::posterior(tidy_lda)$topics)
